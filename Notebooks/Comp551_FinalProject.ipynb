{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comp551_FinalProject.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMoFax2NRUTA8dcTbf04tpm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mohannashahrad/Comp551-Final-Project/blob/main/Notebooks/Comp551_FinalProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixecJ8maFXmy"
      },
      "source": [
        "# Cloning Git repo for reusing the paper code\n",
        "\n",
        "After running this cell, you will find all the frepo content in the Files section of drive (your current session)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-wsosCusnZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2e524d3-dbc2-47eb-a43f-1a8d041cb93c"
      },
      "source": [
        "!git clone https://github.com/mohannashahrad/Comp551-Final-Project.git "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Comp551-Final-Project'...\n",
            "remote: Enumerating objects: 45, done.\u001b[K\n",
            "remote: Counting objects: 100% (45/45), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 45 (delta 5), reused 38 (delta 5), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (45/45), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8Ci7G69G0YQ"
      },
      "source": [
        "# Start rerunning the paper code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQRqmkfdJZ4c"
      },
      "source": [
        "##Changing working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1vHmt_uXJcTi",
        "outputId": "9ffaef8a-e393-49a7-e3c3-44fc3ad2f214"
      },
      "source": [
        "%cd Comp551-Final-Project/Paper_Code/"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Comp551-Final-Project/Paper_Code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJj4fuOAG6eI"
      },
      "source": [
        "## Intsalling the requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hE3wlYC8G5Ie",
        "outputId": "87f0fc62-2312-454d-a60d-049983fb863f"
      },
      "source": [
        "!pip install -r requirements.txt "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.11.1+cu111)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (2.7.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r requirements.txt (line 1)) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->-r requirements.txt (line 2)) (7.1.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.17.3)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.42.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (3.3.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.8.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.12.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (57.4.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (1.35.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->-r requirements.txt (line 3)) (0.37.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard->-r requirements.txt (line 3)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (4.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 3)) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 3)) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r requirements.txt (line 3)) (3.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg4JNp-ZHusv"
      },
      "source": [
        "## Code Organization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQVFawPvH_lz",
        "outputId": "4c1d2a06-9c1d-4c65-d341-f1941697a76b"
      },
      "source": [
        "!python MLP/main.py --help\n",
        "!python ResNet18/main.py --help"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: main.py [-h] [--no_cuda] [--no_BN] [--no_ES] [--make_linear]\n",
            "               [--NTK_style] [--max_epochs MAX_EPOCHS] [--dataset DATASET]\n",
            "               [--dataset_dir DATASET_DIR] [--normalize_pixelwise]\n",
            "               [--model_type {Lin,MLP1}] [--init_distrib {uniform,normal}]\n",
            "               [--no_bias] [--base_width BASE_WIDTH] [--width WIDTH]\n",
            "               [--nwtf_cl NWTF_CL] [--nwtf_fc NWTF_FC] [--lr LR] [--mbs MBS]\n",
            "               [--train_subset_size TRAIN_SUBSET_SIZE] [--seed SEED]\n",
            "               [--output_dir OUTPUT_DIR]\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --no_cuda             disables CUDA\n",
            "  --no_BN               disables BatchNorm\n",
            "  --no_ES               disable Early Stopping\n",
            "  --make_linear         do not apply activation function\n",
            "  --NTK_style           use NTK-style model parametrization\n",
            "  --max_epochs MAX_EPOCHS\n",
            "                        max number of epochs (default: 1\n",
            "  --dataset DATASET     dataset\n",
            "  --dataset_dir DATASET_DIR\n",
            "                        dataset directory\n",
            "  --normalize_pixelwise\n",
            "                        do pixelwise data normalization\n",
            "  --model_type {Lin,MLP1}\n",
            "                        model type (architecture)\n",
            "  --init_distrib {uniform,normal}\n",
            "                        probability distribution for parameter initialization;\n",
            "                        gets overwritten if NTK-style is chosen\n",
            "  --no_bias             no bias in the layers\n",
            "  --base_width BASE_WIDTH\n",
            "                        number of units in the hidden layer in the baseline\n",
            "                        model (default: 56)\n",
            "  --width WIDTH         number of units in the hidden layer in the given\n",
            "                        (sparse) model (default: 56)\n",
            "  --nwtf_cl NWTF_CL     number of weights to freeze in cl layer\n",
            "  --nwtf_fc NWTF_FC     number of weights to freeze in fc layer\n",
            "  --lr LR               learning rate\n",
            "  --mbs MBS             mini-batch size\n",
            "  --train_subset_size TRAIN_SUBSET_SIZE\n",
            "                        number of samples if training on a subset of the\n",
            "                        original train set\n",
            "  --seed SEED           random seed\n",
            "  --output_dir OUTPUT_DIR\n",
            "                        folder name for saving experiment outputs\n",
            "Traceback (most recent call last):\n",
            "  File \"ResNet18/main.py\", line 26, in <module>\n",
            "    from utils import *\n",
            "  File \"/content/Comp551-Final-Project/Paper_Code/ResNet18/utils.py\", line 29, in <module>\n",
            "    import models\n",
            "  File \"/content/Comp551-Final-Project/Paper_Code/ResNet18/models/__init__.py\", line 15, in <module>\n",
            "    from .resnet import *\n",
            "  File \"/content/Comp551-Final-Project/Paper_Code/ResNet18/models/resnet.py\", line 16, in <module>\n",
            "    from third_party.resnet_model.resnet import *\n",
            "ModuleNotFoundError: No module named 'third_party'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us37FegOI4dZ"
      },
      "source": [
        "#Setting the experiment parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YJVcp6ZI6dc",
        "outputId": "21846828-32ae-4f97-fec5-8b4c1fe987a4"
      },
      "source": [
        "%cd MLP/\n",
        "!python generate_args.py\n",
        "#!python Comp551-Final-Project/Paper_Code/ResNet18/generate_args.py"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Comp551-Final-Project/Paper_Code/MLP\n",
            "\n",
            "python -m main --base_width 8 --width 8 --lr 5.0 --seed 1 --nwtf_cl 0 --nwtf_fc 0 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_8_width_8_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 32 --width 32 --lr 80.0 --seed 1 --nwtf_cl 0 --nwtf_fc 0 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_32_width_32_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 8 --width 32 --lr 136.0 --seed 1 --nwtf_cl 0 --nwtf_fc 19056 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_8_width_32_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 128 --width 128 --lr 173.0 --seed 1 --nwtf_cl 0 --nwtf_fc 0 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_128_width_128_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 8 --width 128 --lr 260.0 --seed 1 --nwtf_cl 0 --nwtf_fc 95280 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_8_width_128_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 216 --width 216 --lr 228.0 --seed 1 --nwtf_cl 0 --nwtf_fc 0 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_216_width_216_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 8 --width 216 --lr 361.0 --seed 1 --nwtf_cl 0 --nwtf_fc 165152 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_8_width_216_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 328 --width 328 --lr 306.0 --seed 1 --nwtf_cl 0 --nwtf_fc 0 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_328_width_328_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 8 --width 328 --lr 491.0 --seed 1 --nwtf_cl 0 --nwtf_fc 254080 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_8_width_328_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 512 --width 512 --lr 445.0 --seed 1 --nwtf_cl 0 --nwtf_fc 0 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_512_width_512_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 8 --width 512 --lr 736.0 --seed 1 --nwtf_cl 0 --nwtf_fc 400176 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_8_width_512_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 635 --width 635 --lr 460.0 --seed 1 --nwtf_cl 0 --nwtf_fc 0 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_635_width_635_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n",
            "\n",
            "python -m main --base_width 8 --width 635 --lr 875.0 --seed 1 --nwtf_cl 0 --nwtf_fc 497838 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_8_width_635_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V11vJSr6KApT",
        "outputId": "2ef2aeca-71cf-4338-a74b-c3c881fee962"
      },
      "source": [
        "!python -m main --base_width 8 --width 8 --lr 5.0 --seed 1 --nwtf_cl 0 --nwtf_fc 0 --dataset MNIST --normalize_pixelwise --train_subset_size 2048 --no_ES --max_epochs 300 --mbs 256 --no_bias --NTK_style --no_BN --output_dir MNIST_MLP1__NTK_style_base_8_width_8_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9913344it [00:00, 27380078.19it/s]                 \n",
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "29696it [00:00, 42816793.26it/s]\n",
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1649664it [00:00, 8943904.46it/s]                \n",
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "5120it [00:00, 23702910.02it/s]\n",
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Saving checkpoint as MNIST_MLP1__NTK_style_base_8_width_8_ReLU_no_bias_train_on_2048_samples_pixelwise_normalization_final\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/Comp551-Final-Project/Paper_Code/MLP/main.py\", line 268, in <module>\n",
            "    sshproc.wait()\n",
            "AttributeError: 'NoneType' object has no attribute 'wait'\n"
          ]
        }
      ]
    }
  ]
}